{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "solution.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a3daf2975b62454cb589fd4b07862eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4de135af82f9463cba9384d13cafbf7a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cdd0383643bb4e1faccbe7238b7c35d0",
              "IPY_MODEL_100302e398584795ae30cc8e51eb9c17"
            ]
          }
        },
        "4de135af82f9463cba9384d13cafbf7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cdd0383643bb4e1faccbe7238b7c35d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7318d0cc9b6a464eb00bbfc6e038f280",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100441675,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100441675,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_84c9da1c784440d297d54cb3c065e1c2"
          }
        },
        "100302e398584795ae30cc8e51eb9c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fdb2bac25a0140bfa01d3b114f0cdd5c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 95.8M/95.8M [00:05&lt;00:00, 18.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_69ce4c7b3d234aa6aa0126f950c836a6"
          }
        },
        "7318d0cc9b6a464eb00bbfc6e038f280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "84c9da1c784440d297d54cb3c065e1c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fdb2bac25a0140bfa01d3b114f0cdd5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "69ce4c7b3d234aa6aa0126f950c836a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gaussiandra/NTA_Landmarks_Detection/blob/master/solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvWRpFDLOTto",
        "colab_type": "code",
        "outputId": "4436b8d8-f00e-4fea-a41f-47adf0d5fb6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu May 28 15:53:07 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F50ERnNPolk5",
        "colab_type": "text"
      },
      "source": [
        "## Импорт библиотек"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKM4f8m1ruUy",
        "colab_type": "code",
        "outputId": "75c6506d-2ddb-4ddb-a97b-d6c0729a1ae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "!pip install pretrainedmodels"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pretrainedmodels\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/0e/be6a0e58447ac16c938799d49bfb5fb7a80ac35e137547fc6cee2c08c4cf/pretrainedmodels-0.7.4.tar.gz (58kB)\n",
            "\r\u001b[K     |█████▋                          | 10kB 18.7MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (1.5.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (0.6.0+cu101)\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (4.41.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->pretrainedmodels) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->pretrainedmodels) (1.18.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from munch->pretrainedmodels) (1.12.0)\n",
            "Building wheels for collected packages: pretrainedmodels\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-cp36-none-any.whl size=60962 sha256=75ea6fcafb0a85c05b45d46379a1f6e93a7fbc4bc69a16387b278b6587e985aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/df/63/62583c096289713f22db605aa2334de5b591d59861a02c2ecd\n",
            "Successfully built pretrainedmodels\n",
            "Installing collected packages: munch, pretrainedmodels\n",
            "Successfully installed munch-2.5.0 pretrainedmodels-0.7.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0tHSKHzolk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import pretrainedmodels\n",
        "import os\n",
        "\n",
        "import torch\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import gc\n",
        "import time\n",
        "import random\n",
        "\n",
        "from torch.utils import data\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import tqdm\n",
        "from torch.nn import functional as fnn\n",
        "from torch.utils import data\n",
        "from torchvision import transforms\n",
        "\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e73JB9u2r_7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def restore_landmarks(landmarks, f, margins):\n",
        "    dx, dy = margins\n",
        "    landmarks[:, 0] += dx\n",
        "    landmarks[:, 1] += dy\n",
        "    landmarks /= f\n",
        "    return landmarks\n",
        "\n",
        "\n",
        "def restore_landmarks_batch(landmarks, fs, margins_x, margins_y):\n",
        "    landmarks[:, :, 0] += margins_x[:, None]\n",
        "    landmarks[:, :, 1] += margins_y[:, None]\n",
        "    landmarks /= fs[:, None, None]\n",
        "    return landmarks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srxhE4eiolk-",
        "colab_type": "text"
      },
      "source": [
        "## Параметры"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g42HruAyolk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_SIZE = 0.8\n",
        "NUM_PTS = 194\n",
        "CROP_SIZE = 220\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s4JKCzLsWc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 3462\n",
        "\n",
        "random.seed(SEED)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6eZhsZUollB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM8fknQNBYe1",
        "colab_type": "code",
        "outputId": "6fbb591b-c8c7-4d4f-bc58-6593391f20bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "global_path = '/content/drive/My Drive/ML/NTA Landmarks Detection/'"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyN5e8-2ollE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST_PATH = global_path+\"data/baseline_NTA/data/test/\" \n",
        "TRAIN_PATH = global_path+\"data/baseline_NTA/data/train/\"\n",
        "SUBMISSION_PATH = global_path+\"data/baseline_NTA/data/train/\"\n",
        "LANDMARKS = global_path+\"data/baseline_NTA/data/train/landmarks.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWR2an1_ollH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SUBMISSION_HEADER = \"file_name,Point_M0_X,Point_M0_Y,Point_M1_X,Point_M1_Y,Point_M2_X,Point_M2_Y,Point_M3_X,Point_M3_Y,Point_M4_X,Point_M4_Y,Point_M5_X,Point_M5_Y,Point_M6_X,Point_M6_Y,Point_M7_X,Point_M7_Y,Point_M8_X,Point_M8_Y,Point_M9_X,Point_M9_Y,Point_M10_X,Point_M10_Y,Point_M11_X,Point_M11_Y,Point_M12_X,Point_M12_Y,Point_M13_X,Point_M13_Y,Point_M14_X,Point_M14_Y,Point_M15_X,Point_M15_Y,Point_M16_X,Point_M16_Y,Point_M17_X,Point_M17_Y,Point_M18_X,Point_M18_Y,Point_M19_X,Point_M19_Y,Point_M20_X,Point_M20_Y,Point_M21_X,Point_M21_Y,Point_M22_X,Point_M22_Y,Point_M23_X,Point_M23_Y,Point_M24_X,Point_M24_Y,Point_M25_X,Point_M25_Y,Point_M26_X,Point_M26_Y,Point_M27_X,Point_M27_Y,Point_M28_X,Point_M28_Y,Point_M29_X,Point_M29_Y\\n\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EfKJ4EXollK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "8dcd795c-d11b-4ac9-9c4e-69422d6b3c7f"
      },
      "source": [
        "print(torch.__version__)\n",
        "print(torch.version.cuda)\n",
        "print(torch.backends.cudnn.version())\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.max_memory_allocated(device='cuda'))\n",
        "print(torch.cuda.empty_cache())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.0+cu101\n",
            "10.1\n",
            "7603\n",
            "True\n",
            "1\n",
            "0\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI8tqQZbollO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ScaleMinSideToSize(object):\n",
        "    def __init__(self, size=(CROP_SIZE, CROP_SIZE), elem_name='image'):\n",
        "        self.size = torch.tensor(size, dtype=torch.float)\n",
        "        self.elem_name = elem_name\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        h, w, _ = sample[self.elem_name].shape\n",
        "        if h > w:\n",
        "            f = self.size[0] / w\n",
        "        else:\n",
        "            f = self.size[1] / h\n",
        "\n",
        "        sample[self.elem_name] = cv2.resize(sample[self.elem_name], None, fx=f, fy=f, interpolation=cv2.INTER_AREA)\n",
        "        sample[\"scale_coef\"] = f\n",
        "\n",
        "        if 'landmarks' in sample:\n",
        "            landmarks = sample['landmarks'].reshape(-1, 2).float()\n",
        "            landmarks = landmarks * f\n",
        "            sample['landmarks'] = landmarks.reshape(-1)\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "class CropCenter(object):\n",
        "    def __init__(self, size=128, elem_name='image'):\n",
        "        self.size = size\n",
        "        self.elem_name = elem_name\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        img = sample[self.elem_name]\n",
        "        h, w, _ = img.shape\n",
        "        margin_h = (h - self.size) // 2\n",
        "        margin_w = (w - self.size) // 2\n",
        "        sample[self.elem_name] = img[margin_h:margin_h + self.size, margin_w:margin_w + self.size]\n",
        "        sample[\"crop_margin_x\"] = margin_w\n",
        "        sample[\"crop_margin_y\"] = margin_h\n",
        "\n",
        "        if 'landmarks' in sample:\n",
        "            landmarks = sample['landmarks'].reshape(-1, 2)\n",
        "            landmarks -= torch.tensor((margin_w, margin_h), dtype=landmarks.dtype)[None, :]\n",
        "            sample['landmarks'] = landmarks.reshape(-1)\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "class TransformByKeys(object):\n",
        "    def __init__(self, transform, names):\n",
        "        self.transform = transform\n",
        "        self.names = set(names)\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        for name in self.names:\n",
        "            if name in sample:\n",
        "                sample[name] = self.transform(sample[name])\n",
        "\n",
        "        return sample\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PO8igrgollR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LandmarksDataset(data.Dataset):\n",
        "    def __init__(self, root, transforms, split=\"train\"):\n",
        "        super(LandmarksDataset, self).__init__()\n",
        "        self.root = root\n",
        "        landmark_file_name = os.path.join(root, 'landmarks.csv') if split is not \"test\" \\\n",
        "            else os.path.join(root, \"test_points.csv\")\n",
        "        images_root = os.path.join(root, \"images\")\n",
        "\n",
        "        self.image_names = []\n",
        "        self.landmarks = []\n",
        "\n",
        "        with open(landmark_file_name, \"rt\") as fp:\n",
        "            num_lines = sum(1 for line in fp)\n",
        "        num_lines -= 1  # header\n",
        "\n",
        "        with open(landmark_file_name, \"rt\") as fp:\n",
        "            for i, line in tqdm.tqdm(enumerate(fp)):\n",
        "                if i == 0:\n",
        "                    continue  # skip header\n",
        "                if split == \"train\" and i == int(TRAIN_SIZE * num_lines):\n",
        "                    break  # reached end of train part of data\n",
        "                elif split == \"val\" and i < int(TRAIN_SIZE * num_lines):\n",
        "                    continue  # has not reached start of val part of data\n",
        "                elements = line.strip().split(\",\")\n",
        "                image_name = os.path.join(images_root, elements[0])\n",
        "                self.image_names.append(image_name)\n",
        "\n",
        "                if split in (\"train\", \"val\"):\n",
        "                    landmarks = list(map(np.int16, elements[1:]))\n",
        "                    landmarks = np.array(landmarks, dtype=np.int16).reshape((len(landmarks) // 2, 2))\n",
        "                    self.landmarks.append(landmarks)\n",
        "\n",
        "        if split in (\"train\", \"val\"):\n",
        "            self.landmarks = torch.as_tensor(self.landmarks)\n",
        "        else:\n",
        "            self.landmarks = None\n",
        "\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = {}\n",
        "        if self.landmarks is not None:\n",
        "            landmarks = self.landmarks[idx]\n",
        "            sample[\"landmarks\"] = landmarks\n",
        "\n",
        "        image = cv2.imread(self.image_names[idx])\n",
        "        \n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        sample[\"image\"] = image\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            sample = self.transforms(sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buC-umotollT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, loader, loss_fn, optimizer,  device):\n",
        "    model.train()\n",
        "    train_loss = []\n",
        "    \n",
        "        \n",
        "    for batch in tqdm.tqdm(loader, total=len(loader), desc=\"training...\"):\n",
        "        images = batch[\"image\"].to(device)  # B x 3 x CROP_SIZE x CROP_SIZE\n",
        "        landmarks = batch[\"landmarks\"]  # B x (2 * NUM_PTS)\n",
        "\n",
        "        pred_landmarks = model(images).cpu()  # B x (2 * NUM_PTS)\n",
        "        loss = loss_fn(pred_landmarks, landmarks, reduction=\"mean\")\n",
        "        train_loss.append(loss.item())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return np.mean(train_loss, dtype=np.float64)\n",
        "\n",
        "def validate(model, loader, loss_fn, device):\n",
        "    model.eval()\n",
        "    val_loss = []\n",
        "    for batch in tqdm.tqdm(loader, total=len(loader), desc=\"validation...\"):\n",
        "        images = batch[\"image\"].to(device)\n",
        "        landmarks = batch[\"landmarks\"]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred_landmarks = model(images).cpu()\n",
        "        loss = loss_fn(pred_landmarks, landmarks, reduction=\"mean\")\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "    return np.mean(val_loss, dtype=np.float64)\n",
        "\n",
        "def predict(model, loader, device):\n",
        "    model.eval()\n",
        "    predictions = np.zeros((len(loader.dataset), NUM_PTS, 2))\n",
        "    for i, batch in enumerate(tqdm.tqdm(loader, total=len(loader), desc=\"test prediction...\")):\n",
        "        images = batch[\"image\"].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred_landmarks = model(images).cpu()\n",
        "            pred_landmarks = pred_landmarks.numpy().reshape((len(pred_landmarks), NUM_PTS, 2))  # B x NUM_PTS x 2\n",
        "\n",
        "        fs = batch[\"scale_coef\"].numpy()  # B\n",
        "        margins_x = batch[\"crop_margin_x\"].numpy()  # B\n",
        "        margins_y = batch[\"crop_margin_y\"].numpy()  # B\n",
        "        prediction = restore_landmarks_batch(pred_landmarks, fs, margins_x, margins_y)  # B x NUM_PTS x 2\n",
        "        predictions[i * loader.batch_size: (i + 1) * loader.batch_size] = prediction\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def create_submission(path_to_data, test_predictions, path_to_submission_file):\n",
        "    test_dir = os.path.join(path_to_data)\n",
        "\n",
        "    output_file = path_to_submission_file\n",
        "    wf = open(output_file, 'w')\n",
        "    wf.write(SUBMISSION_HEADER)\n",
        "\n",
        "    mapping_path = os.path.join(test_dir, 'test_points.csv')\n",
        "    mapping = pd.read_csv(mapping_path, delimiter=',')\n",
        "    \n",
        "    for i, row in mapping.iterrows():\n",
        "        \n",
        "        \n",
        "        file_name = row[0]\n",
        "\n",
        "        point_index_list = np.array(eval(row[1]))\n",
        "        points_for_image = test_predictions[i]\n",
        "        needed_points = points_for_image[point_index_list].astype(np.int)\n",
        "        wf.write(file_name + ',' + ','.join(map(str, needed_points.reshape(2 * len(point_index_list)))) + '\\n')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nB6DQlfollW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transforms = transforms.Compose([\n",
        "        ScaleMinSideToSize((CROP_SIZE, CROP_SIZE)),\n",
        "        CropCenter(CROP_SIZE),\n",
        "        TransformByKeys(transforms.ToPILImage(), (\"image\",)),\n",
        "        TransformByKeys(transforms.ToTensor(), (\"image\",)),\n",
        "        TransformByKeys(transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), (\"image\",)),\n",
        "    ])\n",
        "\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "        ScaleMinSideToSize((CROP_SIZE, CROP_SIZE)),\n",
        "        CropCenter(CROP_SIZE),\n",
        "        TransformByKeys(transforms.ToPILImage(), (\"image\",)),\n",
        "        TransformByKeys(transforms.ToTensor(), (\"image\",)),\n",
        "        TransformByKeys(transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), (\"image\",)),\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN7Ck_A0ollZ",
        "colab_type": "code",
        "outputId": "47edf8d9-6b60-4f53-818c-1c6e6ce0ab54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "train_dataset = LandmarksDataset(os.path.join(TRAIN_PATH), train_transforms, split=\"train\")\n",
        "train_dataloader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=0, pin_memory=True,\n",
        "                                   shuffle=True, drop_last=True)\n",
        "val_dataset = LandmarksDataset(os.path.join(TRAIN_PATH), train_transforms, split=\"val\")\n",
        "val_dataloader = data.DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=0, pin_memory=True,\n",
        "                                 shuffle=False, drop_last=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1375it [00:00, 2945.43it/s]\n",
            "2001it [00:00, 16154.05it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMrqjURtollc",
        "colab_type": "code",
        "outputId": "41856cd5-94c4-4276-d952-08b95a8deb26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GTCBIO0ollf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.models as models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Rbrsy2Nollh",
        "colab_type": "code",
        "outputId": "8b8f6634-61a6-4ec5-836e-2d801ab217a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a3daf2975b62454cb589fd4b07862eff",
            "4de135af82f9463cba9384d13cafbf7a",
            "cdd0383643bb4e1faccbe7238b7c35d0",
            "100302e398584795ae30cc8e51eb9c17",
            "7318d0cc9b6a464eb00bbfc6e038f280",
            "84c9da1c784440d297d54cb3c065e1c2",
            "fdb2bac25a0140bfa01d3b114f0cdd5c",
            "69ce4c7b3d234aa6aa0126f950c836a6"
          ]
        }
      },
      "source": [
        "model = models.resnext50_32x4d(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 2 * NUM_PTS, bias=True)\n",
        "model.to(device)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/checkpoints/resnext50_32x4d-7cdf4587.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3daf2975b62454cb589fd4b07862eff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=100441675.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
              "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=388, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXQTJzbAollk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LR = 1e-3\n",
        "EPOCHS = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HubC44Dfollm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=LR, amsgrad=True)\n",
        "loss_fn = fnn.mse_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKbcnxjJAAhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tensorboard + нормальный трейнлуп с параллельной валидацией\n",
        "# Нормальная модель в т.ч. обученная на лицах\n",
        "# Albumenntations\n",
        "# tqdm.notebook\n",
        "# Выглядит, как что-то очень неэффективное("
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ5xuBnaollp",
        "colab_type": "code",
        "outputId": "448436d3-5614-4eb0-905e-edcdcb2df13e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(\"Ready for training...\")\n",
        "best_val_loss = np.inf\n",
        "for epoch in range(5):\n",
        "    train_loss = train(model, train_dataloader, loss_fn, optimizer,  device=device)\n",
        "    val_loss = validate(model, val_dataloader, loss_fn, device=device)\n",
        "    \n",
        "    print(\"Epoch #{:2}:\\ttrain loss: {:10.7}\\tval loss: {:10.7}\".format(epoch, train_loss, val_loss))\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        with open(f\"model.pth\", \"wb\") as fp:\n",
        "            torch.save(model.state_dict(), fp)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "training...:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ready for training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "training...:   4%|▍         | 1/24 [00:03<01:27,  3.81s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:   8%|▊         | 2/24 [00:07<01:21,  3.71s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  12%|█▎        | 3/24 [00:11<01:18,  3.74s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  17%|█▋        | 4/24 [00:14<01:12,  3.60s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  21%|██        | 5/24 [00:17<01:06,  3.49s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  25%|██▌       | 6/24 [00:21<01:04,  3.57s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  29%|██▉       | 7/24 [00:24<00:59,  3.47s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  33%|███▎      | 8/24 [00:28<00:57,  3.61s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  38%|███▊      | 9/24 [00:31<00:53,  3.55s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  42%|████▏     | 10/24 [00:35<00:50,  3.63s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  46%|████▌     | 11/24 [00:39<00:47,  3.64s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  50%|█████     | 12/24 [00:43<00:43,  3.63s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  54%|█████▍    | 13/24 [00:46<00:39,  3.56s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  58%|█████▊    | 14/24 [00:49<00:34,  3.48s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  62%|██████▎   | 15/24 [00:53<00:31,  3.49s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  67%|██████▋   | 16/24 [00:56<00:27,  3.47s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  71%|███████   | 17/24 [01:00<00:24,  3.44s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  75%|███████▌  | 18/24 [01:03<00:21,  3.51s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  79%|███████▉  | 19/24 [01:07<00:17,  3.47s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  83%|████████▎ | 20/24 [01:10<00:14,  3.54s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  88%|████████▊ | 21/24 [01:14<00:10,  3.62s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  92%|█████████▏| 22/24 [01:17<00:06,  3.50s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  96%|█████████▌| 23/24 [01:21<00:03,  3.43s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...: 100%|██████████| 24/24 [01:24<00:00,  3.53s/it]\n",
            "\n",
            "\n",
            "validation...:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  14%|█▍        | 1/7 [00:02<00:17,  2.90s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  29%|██▊       | 2/7 [00:05<00:14,  2.84s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  43%|████▎     | 3/7 [00:08<00:11,  2.90s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  57%|█████▋    | 4/7 [00:11<00:08,  2.83s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  71%|███████▏  | 5/7 [00:14<00:05,  2.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  86%|████████▌ | 6/7 [00:18<00:03,  3.22s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...: 100%|██████████| 7/7 [00:19<00:00,  2.80s/it]\n",
            "\n",
            "\n",
            "training...:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch # 0:\ttrain loss:   272.8394\tval loss:   280.1098\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "training...:   4%|▍         | 1/24 [00:03<01:26,  3.76s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:   8%|▊         | 2/24 [00:07<01:23,  3.77s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  12%|█▎        | 3/24 [00:11<01:18,  3.75s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  17%|█▋        | 4/24 [00:15<01:16,  3.82s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  21%|██        | 5/24 [00:18<01:11,  3.75s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  25%|██▌       | 6/24 [00:23<01:09,  3.89s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  29%|██▉       | 7/24 [00:26<01:04,  3.78s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  33%|███▎      | 8/24 [00:30<01:03,  3.94s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  38%|███▊      | 9/24 [00:34<00:57,  3.80s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  42%|████▏     | 10/24 [00:37<00:51,  3.65s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  46%|████▌     | 11/24 [00:41<00:47,  3.62s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  50%|█████     | 12/24 [00:44<00:41,  3.47s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  54%|█████▍    | 13/24 [00:47<00:37,  3.45s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  58%|█████▊    | 14/24 [00:51<00:34,  3.43s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  62%|██████▎   | 15/24 [00:54<00:30,  3.39s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  67%|██████▋   | 16/24 [00:57<00:25,  3.22s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  71%|███████   | 17/24 [01:00<00:23,  3.29s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  75%|███████▌  | 18/24 [01:03<00:19,  3.28s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  79%|███████▉  | 19/24 [01:07<00:17,  3.44s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  83%|████████▎ | 20/24 [01:12<00:14,  3.72s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  88%|████████▊ | 21/24 [01:15<00:10,  3.65s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  92%|█████████▏| 22/24 [01:18<00:06,  3.48s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  96%|█████████▌| 23/24 [01:22<00:03,  3.48s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...: 100%|██████████| 24/24 [01:25<00:00,  3.56s/it]\n",
            "\n",
            "\n",
            "validation...:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  14%|█▍        | 1/7 [00:02<00:17,  2.90s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  29%|██▊       | 2/7 [00:05<00:14,  2.83s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  43%|████▎     | 3/7 [00:08<00:11,  2.90s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  57%|█████▋    | 4/7 [00:11<00:08,  2.83s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  71%|███████▏  | 5/7 [00:14<00:05,  2.96s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  86%|████████▌ | 6/7 [00:18<00:03,  3.21s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...: 100%|██████████| 7/7 [00:19<00:00,  2.79s/it]\n",
            "\n",
            "\n",
            "training...:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch # 1:\ttrain loss:   262.3299\tval loss:   260.9892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "training...:   4%|▍         | 1/24 [00:03<01:28,  3.87s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:   8%|▊         | 2/24 [00:07<01:21,  3.71s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  12%|█▎        | 3/24 [00:10<01:18,  3.72s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  17%|█▋        | 4/24 [00:14<01:12,  3.64s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  21%|██        | 5/24 [00:18<01:10,  3.71s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  25%|██▌       | 6/24 [00:22<01:07,  3.76s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  29%|██▉       | 7/24 [00:25<01:02,  3.66s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  33%|███▎      | 8/24 [00:29<00:57,  3.60s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  38%|███▊      | 9/24 [00:32<00:52,  3.53s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  42%|████▏     | 10/24 [00:35<00:49,  3.54s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  46%|████▌     | 11/24 [00:39<00:46,  3.60s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  50%|█████     | 12/24 [00:42<00:41,  3.43s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  54%|█████▍    | 13/24 [00:46<00:38,  3.52s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  58%|█████▊    | 14/24 [00:50<00:36,  3.60s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  62%|██████▎   | 15/24 [00:54<00:32,  3.66s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  67%|██████▋   | 16/24 [00:57<00:28,  3.55s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  71%|███████   | 17/24 [01:00<00:24,  3.50s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  75%|███████▌  | 18/24 [01:04<00:21,  3.58s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  79%|███████▉  | 19/24 [01:07<00:17,  3.44s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  83%|████████▎ | 20/24 [01:11<00:14,  3.55s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  88%|████████▊ | 21/24 [01:14<00:10,  3.50s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  92%|█████████▏| 22/24 [01:18<00:06,  3.50s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  96%|█████████▌| 23/24 [01:22<00:03,  3.62s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...: 100%|██████████| 24/24 [01:25<00:00,  3.56s/it]\n",
            "\n",
            "\n",
            "validation...:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  14%|█▍        | 1/7 [00:02<00:17,  2.92s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  29%|██▊       | 2/7 [00:05<00:14,  2.85s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  43%|████▎     | 3/7 [00:08<00:11,  2.91s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  57%|█████▋    | 4/7 [00:11<00:08,  2.84s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  71%|███████▏  | 5/7 [00:14<00:05,  2.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  86%|████████▌ | 6/7 [00:18<00:03,  3.22s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...: 100%|██████████| 7/7 [00:19<00:00,  2.80s/it]\n",
            "\n",
            "\n",
            "training...:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch # 2:\ttrain loss:   240.5679\tval loss:   234.9338\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "training...:   4%|▍         | 1/24 [00:04<01:32,  4.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:   8%|▊         | 2/24 [00:07<01:22,  3.74s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  12%|█▎        | 3/24 [00:10<01:19,  3.77s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  17%|█▋        | 4/24 [00:14<01:13,  3.68s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  21%|██        | 5/24 [00:18<01:11,  3.77s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  25%|██▌       | 6/24 [00:21<01:06,  3.70s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  29%|██▉       | 7/24 [00:25<00:59,  3.51s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  33%|███▎      | 8/24 [00:28<00:55,  3.46s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  38%|███▊      | 9/24 [00:31<00:49,  3.30s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  42%|████▏     | 10/24 [00:34<00:46,  3.32s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  46%|████▌     | 11/24 [00:38<00:44,  3.46s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  50%|█████     | 12/24 [00:42<00:42,  3.56s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  54%|█████▍    | 13/24 [00:45<00:38,  3.48s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  58%|█████▊    | 14/24 [00:49<00:35,  3.52s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  62%|██████▎   | 15/24 [00:52<00:31,  3.47s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  67%|██████▋   | 16/24 [00:55<00:27,  3.42s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  71%|███████   | 17/24 [00:59<00:25,  3.60s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  75%|███████▌  | 18/24 [01:03<00:22,  3.74s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  79%|███████▉  | 19/24 [01:07<00:18,  3.75s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  83%|████████▎ | 20/24 [01:10<00:14,  3.61s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  88%|████████▊ | 21/24 [01:14<00:10,  3.54s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  92%|█████████▏| 22/24 [01:17<00:06,  3.48s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  96%|█████████▌| 23/24 [01:21<00:03,  3.56s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...: 100%|██████████| 24/24 [01:24<00:00,  3.53s/it]\n",
            "\n",
            "\n",
            "validation...:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  14%|█▍        | 1/7 [00:02<00:17,  2.90s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  29%|██▊       | 2/7 [00:05<00:14,  2.83s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  43%|████▎     | 3/7 [00:08<00:11,  2.89s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  57%|█████▋    | 4/7 [00:11<00:08,  2.82s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  71%|███████▏  | 5/7 [00:14<00:05,  2.96s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  86%|████████▌ | 6/7 [00:18<00:03,  3.22s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...: 100%|██████████| 7/7 [00:19<00:00,  2.79s/it]\n",
            "\n",
            "\n",
            "training...:   0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch # 3:\ttrain loss:   212.1433\tval loss:   197.3127\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "training...:   4%|▍         | 1/24 [00:03<01:20,  3.50s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:   8%|▊         | 2/24 [00:06<01:13,  3.36s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  12%|█▎        | 3/24 [00:11<01:17,  3.70s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  17%|█▋        | 4/24 [00:14<01:14,  3.74s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  21%|██        | 5/24 [00:18<01:11,  3.76s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  25%|██▌       | 6/24 [00:21<01:04,  3.59s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  29%|██▉       | 7/24 [00:25<01:00,  3.53s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  33%|███▎      | 8/24 [00:28<00:56,  3.53s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  38%|███▊      | 9/24 [00:31<00:51,  3.41s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  42%|████▏     | 10/24 [00:35<00:49,  3.57s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  46%|████▌     | 11/24 [00:39<00:46,  3.56s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  50%|█████     | 12/24 [00:43<00:44,  3.70s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  54%|█████▍    | 13/24 [00:46<00:39,  3.59s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  58%|█████▊    | 14/24 [00:50<00:35,  3.59s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  62%|██████▎   | 15/24 [00:53<00:31,  3.53s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  67%|██████▋   | 16/24 [00:56<00:27,  3.40s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  71%|███████   | 17/24 [01:00<00:24,  3.50s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  75%|███████▌  | 18/24 [01:03<00:20,  3.39s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  79%|███████▉  | 19/24 [01:07<00:17,  3.44s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  83%|████████▎ | 20/24 [01:10<00:13,  3.45s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  88%|████████▊ | 21/24 [01:14<00:10,  3.57s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  92%|█████████▏| 22/24 [01:18<00:07,  3.59s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...:  96%|█████████▌| 23/24 [01:22<00:03,  3.72s/it]\u001b[A\u001b[A\n",
            "\n",
            "training...: 100%|██████████| 24/24 [01:25<00:00,  3.54s/it]\n",
            "\n",
            "\n",
            "validation...:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  14%|█▍        | 1/7 [00:02<00:17,  2.88s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  29%|██▊       | 2/7 [00:05<00:14,  2.82s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  43%|████▎     | 3/7 [00:08<00:11,  2.89s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  57%|█████▋    | 4/7 [00:11<00:08,  2.82s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  71%|███████▏  | 5/7 [00:14<00:05,  2.96s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...:  86%|████████▌ | 6/7 [00:18<00:03,  3.22s/it]\u001b[A\u001b[A\n",
            "\n",
            "validation...: 100%|██████████| 7/7 [00:19<00:00,  2.79s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch # 4:\ttrain loss:   192.4275\tval loss:   269.1752\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUJgBDMvollt",
        "colab_type": "code",
        "outputId": "965195b1-a818-4c4e-c9ed-6ffbba2ce818",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "test_dataset = LandmarksDataset(os.path.join(TEST_PATH), test_transforms, split=\"test\")\n",
        "test_dataloader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=0, pin_memory=True,\n",
        "                                  shuffle=False, drop_last=False)\n",
        "\n",
        "with open(f\"model.pth\", \"rb\") as fp:\n",
        "    best_state_dict = torch.load(fp, map_location=\"cpu\")\n",
        "    model.load_state_dict(best_state_dict)\n",
        "\n",
        "test_predictions = predict(model, test_dataloader, device)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "331it [00:00, 80594.14it/s]\n",
            "\n",
            "\n",
            "test prediction...:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "test prediction...:  17%|█▋        | 1/6 [00:24<02:03, 24.61s/it]\u001b[A\u001b[A\n",
            "\n",
            "test prediction...:  33%|███▎      | 2/6 [00:42<01:30, 22.63s/it]\u001b[A\u001b[A\n",
            "\n",
            "test prediction...:  50%|█████     | 3/6 [01:02<01:05, 21.67s/it]\u001b[A\u001b[A\n",
            "\n",
            "test prediction...:  67%|██████▋   | 4/6 [01:21<00:41, 20.95s/it]\u001b[A\u001b[A\n",
            "\n",
            "test prediction...:  83%|████████▎ | 5/6 [01:40<00:20, 20.27s/it]\u001b[A\u001b[A\n",
            "\n",
            "test prediction...: 100%|██████████| 6/6 [01:42<00:00, 17.12s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_K-shTUKollv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(global_path+\"test_predictions.pkl\", \"wb\") as fp:\n",
        "    pickle.dump({\"image_names\": test_dataset.image_names,\n",
        "                 \"landmarks\": test_predictions}, fp)\n",
        "\n",
        "create_submission(TEST_PATH, test_predictions, f\"submit.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VX4011ybollx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}